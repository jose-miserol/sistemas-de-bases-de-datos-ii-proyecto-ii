{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 04: Validaci√≥n y M√©tricas de Rendimiento\n",
    "# **Universidad:** Universidad Nacional Experimental de Guayana (UNEG)  \n",
    "# **Asignatura:** Sistemas de Bases de Datos II  \n",
    "# **Proyecto:** Proyecto N2 - Data Pipeline Escalable\n",
    "# ---\n",
    "# **Descripci√≥n:**  \n",
    "# Valida las m√©tricas de rendimiento y ejecuta consultas anal√≠ticas en ClickHouse.\n",
    "# Este notebook recopila **autom√°ticamente** las m√©tricas de los notebooks anteriores.\n",
    "# **Prerrequisitos:**\n",
    "# - Ejecutar `02_generador_datos.ipynb`\n",
    "# - Ejecutar `03_etl_spark.ipynb`\n",
    "# - Los notebooks anteriores guardan sus tiempos en `../docs/metricas.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Fecha de ejecuci√≥n: 2026-02-09 21:33:52\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Archivo de m√©tricas compartido (directorio docs montado por Docker)\n",
    "METRICS_FILE = '../docs/metricas.json'\n",
    "\n",
    "print(f\"üìÖ Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ M√©tricas cargadas autom√°ticamente desde notebooks anteriores\n",
      "\n",
      "üìã Contenido de ../docs/metricas.json:\n",
      "{\n",
      "  \"ingesta_cassandra\": {\n",
      "    \"tiempo_segundos\": 13.17,\n",
      "    \"registros\": 100000,\n",
      "    \"tasa_regs_seg\": 7590.24,\n",
      "    \"timestamp\": \"2026-02-09T21:32:58.089691\"\n",
      "  },\n",
      "  \"etl_spark\": {\n",
      "    \"tiempo_lectura\": 0.34,\n",
      "    \"tiempo_transformacion\": 0.89,\n",
      "    \"tiempo_escritura\": 0.86,\n",
      "    \"tiempo_total\": 2.09,\n",
      "    \"registros_entrada\": 100000,\n",
      "    \"registros_salida\": 5490,\n",
      "    \"timestamp\": \"2026-02-09T21:33:40.710514\"\n",
      "  },\n",
      "  \"consultas_clickhouse\": {\n",
      "    \"consulta_top10\": 0.0128,\n",
      "    \"consulta_promedio\": 0.0096,\n",
      "    \"registros_analizados\": 5651,\n",
      "    \"timestamp\": \"2026-02-07T16:32:24.060014\"\n",
      "  }\n",
      "}\n",
      "\n",
      "üïê Tiempos extra√≠dos:\n",
      "   - Ingesta Cassandra: 13.17 seg\n",
      "   - ETL Spark Total:   2.09 seg\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# üì• CARGAR M√âTRICAS AUTOM√ÅTICAMENTE\n",
    "# =====================================================\n",
    "\n",
    "if os.path.exists(METRICS_FILE):\n",
    "    with open(METRICS_FILE, 'r') as f:\n",
    "        metricas = json.load(f)\n",
    "    print(\"‚úÖ M√©tricas cargadas autom√°ticamente desde notebooks anteriores\")\n",
    "    print(f\"\\nüìã Contenido de {METRICS_FILE}:\")\n",
    "    print(json.dumps(metricas, indent=2))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontr√≥ el archivo de m√©tricas.\")\n",
    "    print(\"   Ejecuta primero los notebooks 02 y 03.\")\n",
    "    metricas = {}\n",
    "\n",
    "# Extraer valores para usar en el resumen\n",
    "tiempo_ingesta = metricas.get('ingesta_cassandra', {}).get('tiempo_segundos', 0)\n",
    "tiempo_etl = metricas.get('etl_spark', {}).get('tiempo_total', 0)\n",
    "\n",
    "print(f\"\\nüïê Tiempos extra√≠dos:\")\n",
    "print(f\"   - Ingesta Cassandra: {tiempo_ingesta:.2f} seg\")\n",
    "print(f\"   - ETL Spark Total:   {tiempo_etl:.2f} seg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conectado a ClickHouse\n",
      "   - Registros en ventas_resumen: 7,980\n"
     ]
    }
   ],
   "source": [
    "# Instalar cliente si no existe\n",
    "!pip install -q clickhouse-connect\n",
    "\n",
    "import clickhouse_connect\n",
    "\n",
    "# Conectar a ClickHouse\n",
    "client = clickhouse_connect.get_client(\n",
    "    host='clickhouse',\n",
    "    port=8123,\n",
    "    database='dw_analitico'\n",
    ")\n",
    "\n",
    "# Verificar conexi√≥n\n",
    "result = client.query(\"SELECT COUNT(*) as total FROM ventas_resumen\")\n",
    "total_registros = result.result_rows[0][0]\n",
    "print(f\"‚úÖ Conectado a ClickHouse\")\n",
    "print(f\"   - Registros en ventas_resumen: {total_registros:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Consulta Top 10 ---\n",
      "‚è±Ô∏è Tiempo de ejecuci√≥n: 0.0278 segundos\n",
      "\n",
      "üìä Resultados:\n",
      "----------------------------------------\n",
      "  Mascotas: $4,244,727.13\n",
      "  Jardin: $4,241,456.22\n",
      "  Libros: $4,188,035.86\n",
      "  Belleza: $4,168,598.34\n",
      "  Videojuegos: $4,165,744.96\n",
      "  Automotriz: $4,161,815.88\n",
      "  Ropa: $4,149,082.77\n",
      "  Deportes: $4,146,430.15\n",
      "  Electronica: $4,139,323.63\n",
      "  Salud: $4,113,339.42\n"
     ]
    }
   ],
   "source": [
    "query_top10 = \"\"\"\n",
    "SELECT \n",
    "    categoria,\n",
    "    sum(ventas_totales) as total_ventas_periodo\n",
    "FROM dw_analitico.ventas_resumen\n",
    "GROUP BY categoria\n",
    "ORDER BY total_ventas_periodo DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Ejecutando Consulta Top 10 ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "result_top10 = client.query(query_top10)\n",
    "\n",
    "end_time = time.time()\n",
    "tiempo_consulta_top10 = end_time - start_time\n",
    "\n",
    "print(f\"‚è±Ô∏è Tiempo de ejecuci√≥n: {tiempo_consulta_top10:.4f} segundos\")\n",
    "print(\"\\nüìä Resultados:\")\n",
    "print(\"-\" * 40)\n",
    "for row in result_top10.result_rows:\n",
    "    print(f\"  {row[0]}: ${row[1]:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Consulta Promedio Diario ---\n",
      "‚è±Ô∏è Tiempo de ejecuci√≥n: 0.0079 segundos\n",
      "\n",
      "üìä Resultados:\n",
      "------------------------------------------------------------\n",
      "  Alimentos: Promedio $7,487.93 | Transacciones: 9,378\n",
      "  Automotriz: Promedio $7,822.96 | Transacciones: 9,863\n",
      "  Belleza: Promedio $7,895.07 | Transacciones: 9,744\n",
      "  Cine: Promedio $7,691.39 | Transacciones: 9,552\n",
      "  Deportes: Promedio $7,823.45 | Transacciones: 9,712\n",
      "  Electronica: Promedio $7,737.05 | Transacciones: 9,955\n",
      "  Hogar: Promedio $7,686.87 | Transacciones: 9,624\n",
      "  Jardin: Promedio $7,972.66 | Transacciones: 9,820\n",
      "  Juguetes: Promedio $7,678.36 | Transacciones: 9,611\n",
      "  Libros: Promedio $7,828.10 | Transacciones: 9,694\n",
      "  Mascotas: Promedio $8,039.26 | Transacciones: 9,785\n",
      "  Musica: Promedio $7,639.86 | Transacciones: 9,478\n",
      "  Ropa: Promedio $7,769.82 | Transacciones: 9,719\n",
      "  Salud: Promedio $7,746.40 | Transacciones: 9,648\n",
      "  Videojuegos: Promedio $7,771.91 | Transacciones: 9,770\n"
     ]
    }
   ],
   "source": [
    "query_promedio = \"\"\"\n",
    "SELECT \n",
    "    categoria,\n",
    "    avg(ventas_totales) as promedio_ventas_diarias,\n",
    "    sum(cantidad_transacciones) as transacciones_totales\n",
    "FROM dw_analitico.ventas_resumen\n",
    "GROUP BY categoria\n",
    "ORDER BY categoria\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Ejecutando Consulta Promedio Diario ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "result_promedio = client.query(query_promedio)\n",
    "\n",
    "end_time = time.time()\n",
    "tiempo_consulta_promedio = end_time - start_time\n",
    "\n",
    "print(f\"‚è±Ô∏è Tiempo de ejecuci√≥n: {tiempo_consulta_promedio:.4f} segundos\")\n",
    "print(\"\\nüìä Resultados:\")\n",
    "print(\"-\" * 60)\n",
    "for row in result_promedio.result_rows:\n",
    "    print(f\"  {row[0]}: Promedio ${row[1]:,.2f} | Transacciones: {row[2]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. üìã RESUMEN FINAL DE M√âTRICAS (PARA EL INFORME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä RESUMEN DE M√âTRICAS DE RENDIMIENTO - PROYECTO DATA PIPELINE\n",
      "======================================================================\n",
      "\n",
      "üñ•Ô∏è Entorno de Ejecuci√≥n:\n",
      "   - Plataforma: Docker Container\n",
      "   - Python: 3.11.6\n",
      "   - Fecha: 2026-02-09 21:34:13\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üìà TABLA DE TIEMPOS (Copiar al informe):\n",
      "\n",
      "| Operaci√≥n                  | Tiempo Real | Objetivo    | Cumple |\n",
      "|:---------------------------|:-----------:|:-----------:|:------:|\n",
      "| Ingesta Cassandra (100k)   |    13.17 s  | < 5 min     | ‚úÖ     |\n",
      "| Transformaci√≥n Spark ETL   |     2.09 s  | < 2 min     | ‚úÖ     |\n",
      "| Consulta Top 10 (CH)       |   0.0278 s  | < 3 seg     | ‚úÖ     |\n",
      "| Consulta Promedio (CH)     |   0.0079 s  | < 3 seg     | ‚úÖ     |\n",
      "\n",
      "======================================================================\n",
      "üí° CONCLUSI√ìN:\n",
      "   ‚úÖ TODOS los objetivos de rendimiento fueron CUMPLIDOS.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä RESUMEN DE M√âTRICAS DE RENDIMIENTO - PROYECTO DATA PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüñ•Ô∏è Entorno de Ejecuci√≥n:\")\n",
    "print(f\"   - Plataforma: Docker Container\")\n",
    "print(f\"   - Python: {platform.python_version()}\")\n",
    "print(f\"   - Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Objetivos\n",
    "obj_ingesta = 300  # 5 minutos\n",
    "obj_etl = 120  # 2 minutos\n",
    "obj_query = 3  # 3 segundos\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"\\nüìà TABLA DE TIEMPOS (Copiar al informe):\")\n",
    "print(\"\\n| Operaci√≥n                  | Tiempo Real | Objetivo    | Cumple |\")\n",
    "print(\"|:---------------------------|:-----------:|:-----------:|:------:|\")\n",
    "\n",
    "# Ingesta\n",
    "cumple_ing = \"‚úÖ\" if tiempo_ingesta < obj_ingesta else \"‚ùå\"\n",
    "print(f\"| Ingesta Cassandra (100k)   | {tiempo_ingesta:>8.2f} s  | < 5 min     | {cumple_ing}     |\")\n",
    "\n",
    "# ETL\n",
    "cumple_etl = \"‚úÖ\" if tiempo_etl < obj_etl else \"‚ùå\"\n",
    "print(f\"| Transformaci√≥n Spark ETL   | {tiempo_etl:>8.2f} s  | < 2 min     | {cumple_etl}     |\")\n",
    "\n",
    "# Consulta Top 10\n",
    "cumple_q1 = \"‚úÖ\" if tiempo_consulta_top10 < obj_query else \"‚ùå\"\n",
    "print(f\"| Consulta Top 10 (CH)       | {tiempo_consulta_top10:>8.4f} s  | < 3 seg     | {cumple_q1}     |\")\n",
    "\n",
    "# Consulta Promedio\n",
    "cumple_q2 = \"‚úÖ\" if tiempo_consulta_promedio < obj_query else \"‚ùå\"\n",
    "print(f\"| Consulta Promedio (CH)     | {tiempo_consulta_promedio:>8.4f} s  | < 3 seg     | {cumple_q2}     |\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üí° CONCLUSI√ìN:\")\n",
    "todos_cumplen = all([\n",
    "    tiempo_ingesta < obj_ingesta, \n",
    "    tiempo_etl < obj_etl, \n",
    "    tiempo_consulta_top10 < obj_query, \n",
    "    tiempo_consulta_promedio < obj_query\n",
    "])\n",
    "if todos_cumplen:\n",
    "    print(\"   ‚úÖ TODOS los objetivos de rendimiento fueron CUMPLIDOS.\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Algunos objetivos NO fueron cumplidos. Revisar configuraci√≥n.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exportar M√©tricas Finales a Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ M√©tricas exportadas a:\n",
      "   - JSON: ../docs/metricas.json\n",
      "   - Markdown: ../docs/metricas_reales.md\n",
      "\n",
      "üìù El informe se ha generado autom√°ticamente en ../docs/metricas_reales.md.\n"
     ]
    }
   ],
   "source": [
    "# Actualizar archivo de m√©tricas con consultas\n",
    "metricas['consultas_clickhouse'] = {\n",
    "    'consulta_top10': round(tiempo_consulta_top10, 4),\n",
    "    'consulta_promedio': round(tiempo_consulta_promedio, 4),\n",
    "    'registros_analizados': total_registros,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(METRICS_FILE, 'w') as f:\n",
    "    json.dump(metricas, f, indent=2)\n",
    "\n",
    "# Generar archivo Markdown para el informe (en el mismo directorio)\n",
    "output_md = '../docs/metricas_reales.md'\n",
    "\n",
    "with open(output_md, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# üìä M√©tricas de Rendimiento - Valores Reales\\n\\n\")\n",
    "    f.write(f\"**Fecha de ejecuci√≥n:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    \n",
    "    # 1. Diagrama de Arquitectura\n",
    "    f.write(\"## 1. Diagrama de Arquitectura de Datos\\n\\n\")\n",
    "    f.write(\"```mermaid\\n\")\n",
    "    f.write(\"graph LR\\n\")\n",
    "    f.write(\"    A[Fuente de Datos] -->|Generador Python| B(Cassandra OLTP)\\n\")\n",
    "    f.write(\"    B -->|Ingesta Paralela| C{Apache Spark}\\n\")\n",
    "    f.write(\"    C -->|Transformaci√≥n ETL| D(ClickHouse OLAP)\\n\")\n",
    "    f.write(\"    D -->|Consultas SQL| E[Reporte Anal√≠tico]\\n\")\n",
    "    f.write(\"    style B fill:#1f77b4,stroke:#333,stroke-width:2px,color:white\\n\")\n",
    "    f.write(\"    style C fill:#d62728,stroke:#333,stroke-width:2px,color:white\\n\")\n",
    "    f.write(\"    style D fill:#ff7f0e,stroke:#333,stroke-width:2px,color:white\\n\")\n",
    "    f.write(\"```\\n\\n\")\n",
    "    \n",
    "    # 2. Tabla Comparativa\n",
    "    f.write(\"## 2. Tabla Comparativa de Rendimiento\\n\\n\")\n",
    "    f.write(\"| Operaci√≥n | Tiempo Real | Objetivo | Cumple |\\n\")\n",
    "    f.write(\"|:---|:---:|:---:|:---:|\\n\")\n",
    "    f.write(f\"| Ingesta Cassandra (100k) | {tiempo_ingesta:.2f} s | < 5 min | {'‚úÖ' if tiempo_ingesta < 300 else '‚ùå'} |\\n\")\n",
    "    f.write(f\"| Transformaci√≥n Spark ETL | {tiempo_etl:.2f} s | < 2 min | {'‚úÖ' if tiempo_etl < 120 else '‚ùå'} |\\n\")\n",
    "    f.write(f\"| Consulta Top 10 (ClickHouse) | {tiempo_consulta_top10:.4f} s | < 3 seg | {'‚úÖ' if tiempo_consulta_top10 < 3 else '‚ùå'} |\\n\")\n",
    "    f.write(f\"| Consulta Promedio (ClickHouse) | {tiempo_consulta_promedio:.4f} s | < 3 seg | {'‚úÖ' if tiempo_consulta_promedio < 3 else '‚ùå'} |\\n\")\n",
    "    \n",
    "    # 3. Detalles\n",
    "    f.write(\"\\n## 3. Detalles de Ejecuci√≥n\\n\\n\")\n",
    "    f.write(f\"- **Registros insertados en Cassandra:** {metricas.get('ingesta_cassandra', {}).get('registros', 'N/A'):,}\\n\")\n",
    "    f.write(f\"- **Registros procesados por Spark:** {metricas.get('etl_spark', {}).get('registros_entrada', 'N/A'):,}\\n\")\n",
    "    f.write(f\"- **Registros en ClickHouse:** {total_registros:,}\\n\")\n",
    "    \n",
    "    # 4. An√°lisis Comparativo\n",
    "    f.write(\"\\n## 4. An√°lisis Comparativo: Cassandra vs ClickHouse\\n\\n\")\n",
    "    f.write(\"### ¬øPor qu√© Cassandra para la Ingesta (OLTP)?\\n\")\n",
    "    f.write(\"- **Escritura Optimizada:** Su arquitectura *Log-Structured Merge Tree* permite escrituras masivas secuenciales extremadamente r√°pidas.\\n\")\n",
    "    f.write(\"- **Disponibilidad:** Su dise√±o *masterless* garantiza que el sistema siempre acepte escrituras, ideal para la captura de datos en tiempo real.\\n\")\n",
    "    f.write(\"- **Escalabilidad Lineal:** Permite agregar nodos para aumentar la capacidad de escritura sin tiempos de inactividad.\\n\\n\")\n",
    "    f.write(\"### ¬øPor qu√© ClickHouse para Anal√≠tica (OLAP)?\\n\")\n",
    "    f.write(\"- **Almacenamiento Columnar:** Lee solo las columnas necesarias para la consulta (ej. `monto_total`), ignorando el resto, lo que acelera dram√°ticamente las agregaciones.\\n\")\n",
    "    f.write(\"- **Compresi√≥n de Datos:** Almacena columnas de tipos similares juntas, logrando tasas de compresi√≥n altas y reduciendo E/S de disco.\\n\")\n",
    "    f.write(\"- **Motores de Agregaci√≥n:** Utiliza instrucciones vectoriales (SIMD) para procesar millones de filas en milisegundos, como se evidencia en los tiempos de consulta (< 0.02s).\\n\")\n",
    "\n",
    "print(f\"‚úÖ M√©tricas exportadas a:\")\n",
    "print(f\"   - JSON: {METRICS_FILE}\")\n",
    "print(f\"   - Markdown: {output_md}\")\n",
    "print(f\"\\nüìù El informe se ha generado autom√°ticamente en {output_md}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
