{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "spark_init",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, sum, count\n",
        "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, DecimalType, DateType, IntegerType\n",
        "\n",
        "# Configuraci√≥n de Spark con conectores de Cassandra y ClickHouse\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ETL_Cassandra_Spark_ClickHouse\") \\\n",
        "    .config(\"spark.jars.packages\", \"com.datastax.spark:spark-cassandra-connector_2.12:3.5.0,com.clickhouse:clickhouse-jdbc:0.5.0\") \\\n",
        "    .config(\"spark.cassandra.connection.host\", \"cassandra\") \\\n",
        "    .config(\"spark.cassandra.connection.localDC\", \"dc1\") \\\n",
        "    .config(\"spark.driver.memory\", \"2g\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "read_cassandra",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 1. Leyendo datos de Cassandra (ventas_db.ventas_crudas) ---\n",
            "‚úÖ Lectura completada en 0.98 segundos\n",
            "Total de registros crudos: 280012\n",
            "root\n",
            " |-- fecha_venta: timestamp (nullable = false)\n",
            " |-- categoria: string (nullable = true)\n",
            " |-- id_cliente: string (nullable = true)\n",
            " |-- id_producto: string (nullable = true)\n",
            " |-- id_venta: string (nullable = true)\n",
            " |-- monto_total: decimal(38,18) (nullable = true)\n",
            "\n",
            "+-------------------+-----------+----------+-----------+--------------------+--------------------+\n",
            "|        fecha_venta|  categoria|id_cliente|id_producto|            id_venta|         monto_total|\n",
            "+-------------------+-----------+----------+-----------+--------------------+--------------------+\n",
            "|2024-02-06 10:37:00|Electronica|   CLI-189|   PROD-918|63f71c34-fd47-44b...|414.6400000000000...|\n",
            "|2024-12-14 02:35:00|  Alimentos|   CLI-192|   PROD-804|6920e5a7-3109-45c...|702.9500000000000...|\n",
            "|2024-03-08 06:09:00|Electronica|   CLI-487|   PROD-466|5f9e5a47-59b4-457...|1459.320000000000...|\n",
            "|2024-09-09 04:49:00|      Hogar|     CLI-1|   PROD-535|56dd7210-17db-465...|695.9100000000000...|\n",
            "|2024-12-21 23:15:00|  Alimentos|   CLI-389|   PROD-303|44290ddb-cece-413...|824.2800000000000...|\n",
            "+-------------------+-----------+----------+-----------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"--- 1. Leyendo datos de Cassandra (ventas_db.ventas_crudas) ---\")\n",
        "start_read = time.time()\n",
        "\n",
        "df_raw = spark.read \\\n",
        "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
        "    .options(table=\"ventas_crudas\", keyspace=\"ventas_db\") \\\n",
        "    .load()\n",
        "\n",
        "count_raw = df_raw.count()\n",
        "end_read = time.time()\n",
        "\n",
        "print(f\"‚úÖ Lectura completada en {end_read - start_read:.2f} segundos\")\n",
        "print(f\"Total de registros crudos: {count_raw}\")\n",
        "df_raw.printSchema()\n",
        "df_raw.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "transform",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 2. Transformando datos (Agregaci√≥n por Fecha y Categor√≠a) ---\n",
            "‚úÖ Transformaci√≥n completada en 1.56 segundos\n",
            "Total de filas agregadas: 1830\n",
            "+-----------+-----------+--------------+----------------------+\n",
            "|fecha_venta|  categoria|ventas_totales|cantidad_transacciones|\n",
            "+-----------+-----------+--------------+----------------------+\n",
            "| 2024-07-21|  Alimentos|      99253.84|                   130|\n",
            "| 2024-10-30|   Deportes|     127066.25|                   161|\n",
            "| 2024-01-16|Electronica|     111586.49|                   154|\n",
            "| 2024-07-02|      Hogar|     112151.44|                   144|\n",
            "| 2024-01-22|      Hogar|     110991.60|                   146|\n",
            "+-----------+-----------+--------------+----------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"--- 2. Transformando datos (Agregaci√≥n por Fecha y Categor√≠a) ---\")\n",
        "start_transform = time.time()\n",
        "\n",
        "# Transformaci√≥n: Casting, GroupBy, Aggregation\n",
        "df_aggregated = df_raw \\\n",
        "    .withColumn(\"fecha_dia\", col(\"fecha_venta\").cast(DateType())) \\\n",
        "    .groupBy(\"fecha_dia\", \"categoria\") \\\n",
        "    .agg(\n",
        "        sum(\"monto_total\").alias(\"ventas_totales\"),\n",
        "        count(\"id_venta\").alias(\"cantidad_transacciones\")\n",
        "    )\n",
        "\n",
        "df_result = df_aggregated.select(\n",
        "    col(\"fecha_dia\").alias(\"fecha_venta\"),\n",
        "    col(\"categoria\"),\n",
        "    col(\"ventas_totales\").cast(DecimalType(18, 2)),\n",
        "    col(\"cantidad_transacciones\").cast(IntegerType())\n",
        ")\n",
        "\n",
        "# Forzamos una acci√≥n para medir el tiempo real de transformaci√≥n (Spark es lazy)\n",
        "count_result = df_result.count()\n",
        "end_transform = time.time()\n",
        "\n",
        "print(f\"‚úÖ Transformaci√≥n completada en {end_transform - start_transform:.2f} segundos\")\n",
        "print(f\"Total de filas agregadas: {count_result}\")\n",
        "df_result.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "write_clickhouse",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- 3. Escribiendo en ClickHouse (dw_analitico.ventas_resumen) ---\n",
            "‚úÖ Carga en ClickHouse exitosa en 1.49 segundos\n"
          ]
        }
      ],
      "source": [
        "print(\"--- 3. Escribiendo en ClickHouse (dw_analitico.ventas_resumen) ---\")\n",
        "start_write = time.time()\n",
        "\n",
        "jdbc_url = \"jdbc:clickhouse://clickhouse:8123/dw_analitico\"\n",
        "properties = {\n",
        "    \"driver\": \"com.clickhouse.jdbc.ClickHouseDriver\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    df_result.write \\\n",
        "        .mode(\"append\") \\\n",
        "        .jdbc(url=jdbc_url, table=\"ventas_resumen\", properties=properties)\n",
        "    \n",
        "    end_write = time.time()\n",
        "    print(f\"‚úÖ Carga en ClickHouse exitosa en {end_write - start_write:.2f} segundos\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error al escribir en ClickHouse: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "metrics_summary",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- üìä Resumen de M√©tricas de Rendimiento ---\n",
            "1. Lectura (Cassandra):    0.98 s\n",
            "2. Transformaci√≥n (Spark): 1.56 s\n",
            "3. Carga (ClickHouse):     1.49 s\n",
            "-------------------------------------------\n",
            "Tiempo Total ETL:          4.03 s\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Resumen de M√©tricas de Rendimiento ---\")\n",
        "print(f\"1. Lectura (Cassandra):    {end_read - start_read:.2f} s\")\n",
        "print(f\"2. Transformaci√≥n (Spark): {end_transform - start_transform:.2f} s\")\n",
        "print(f\"3. Carga (ClickHouse):     {end_write - start_write:.2f} s\")\n",
        "print(f\"-------------------------------------------\")\n",
        "print(f\"Tiempo Total ETL:          {(end_read - start_read) + (end_transform - start_transform) + (end_write - start_write):.2f} s\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
