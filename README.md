<div align="center">

# ğŸš€ Scalable Big Data Pipeline & Analytics

![Cassandra](https://img.shields.io/badge/Cassandra-1287B1?style=for-the-badge&logo=apache-cassandra&logoColor=white)
![Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)
![ClickHouse](https://img.shields.io/badge/ClickHouse-F9D71C?style=for-the-badge&logo=clickhouse&logoColor=black)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)

### ğŸ“š Universidad Nacional Experimental de Guayana (UNEG)

**Sistemas de Bases de Datos II â€¢ Proyecto NÂ° 2 â€¢ Semestre 2025-II**

</div>

---

## ï¿½ DescripciÃ³n del Proyecto

ImplementaciÃ³n de un **Data Pipeline completo** que demuestra la integraciÃ³n de tecnologÃ­as NoSQL (Apache Cassandra), procesamiento distribuido (Apache Spark) y almacenamiento analÃ­tico (ClickHouse) para simular un sistema de ingesta y anÃ¡lisis de grandes volÃºmenes de datos.

### ğŸ¯ Objetivo

DiseÃ±ar, implementar y validar un prototipo funcional de arquitectura de datos escalable que simula:

- **Carga de grandes volÃºmenes** de datos transaccionales (NoSQL)
- **Procesamiento distribuido y paralelo** de datos (Spark)
- **Almacenamiento analÃ­tico** para generaciÃ³n de informes (Data Warehouse)

---

## ğŸ—ï¸ Arquitectura del Sistema

```mermaid
graph LR
    A[Generador de Datos] -->|100k registros| B[Apache Cassandra]
    B -->|Lectura paralela| C[Apache Spark]
    C -->|TransformaciÃ³n ETL| D[ClickHouse]
    D -->|Consultas analÃ­ticas| E[Reportes]

    style B fill:#1168bd
    style C fill:#e25a1c
    style D fill:#f9d71c
```

| Capa                | TecnologÃ­a             | Rol                                            | Tipo   |
| ------------------- | ---------------------- | ---------------------------------------------- | ------ |
| **Ingesta**         | Apache Cassandra       | Almacenamiento de datos transaccionales crudos | OLTP   |
| **TransformaciÃ³n**  | Apache Spark (PySpark) | Procesamiento, limpieza y agregaciÃ³n paralela  | ELT    |
| **AnalÃ­tica**       | ClickHouse             | Data Warehouse para consultas y reportes       | OLAP   |
| **Infraestructura** | Docker Compose         | OrquestaciÃ³n y despliegue de servicios         | DevOps |

---

## ğŸ“ Estructura del Proyecto

```
proyecto_bigdata/
â”œâ”€â”€ docker-compose.yml              # DefiniciÃ³n de servicios Docker
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ cassandra/
â”‚   â”‚   â””â”€â”€ schema.cql              # Esquema de tabla ventas_crudas
â”‚   â””â”€â”€ clickhouse/
â”‚       â””â”€â”€ schema.sql              # Esquema de tabla ventas_resumen
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_connection.ipynb         # ValidaciÃ³n de conectividad
â”‚   â”œâ”€â”€ 02_generador_datos.ipynb    # GeneraciÃ³n e ingesta de datos
â”‚   â”œâ”€â”€ 03_etl_spark.ipynb          # Pipeline ETL con PySpark
â”‚   â””â”€â”€ 04_validacion_metricas.ipynb # ValidaciÃ³n y consultas analÃ­ticas
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ metricas.json               # MÃ©tricas de ejecuciÃ³n (JSON)
â”‚   â”œâ”€â”€ metricas_reales.md          # Informe de mÃ©tricas (Markdown)
â”‚   â”œâ”€â”€ consultas_analiticas.sql    # Scripts SQL de consultas
â”‚   â”œâ”€â”€ sistema_de_bases_de_datos...pdf # Informe final del proyecto
â”‚   â””â”€â”€ screenshot-v1...v4.jpeg     # Evidencia de ejecuciÃ³n
â””â”€â”€ README.md                       # Este archivo
```

---

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

- **Docker** instalado segÃºn sistema operativo:
  - **Windows/Mac:** [Docker Desktop](https://www.docker.com/products/docker-desktop/) (incluye Docker Engine + Docker Compose)
  - **Linux:** [Docker Engine](https://docs.docker.com/engine/install/) + [Docker Compose](https://docs.docker.com/compose/install/)
- MÃ­nimo **8 GB RAM** disponibles para los contenedores
- **20 GB** de espacio en disco
- **Recomendado:** CPU con 4+ cores para mejor rendimiento de Spark

### Pasos de InstalaciÃ³n

1. **Clonar/crear el directorio del proyecto:**

   ```bash
   mkdir sistemas-de-bases-de-datos-ii-proyecto-ii
   cd sistemas-de-bases-de-datos-ii-proyecto-ii
   ```

2. **Levantar los servicios:**

   ```bash
   docker-compose up -d
   ```

3. **Verificar que todos los servicios estÃ©n corriendo:**

   ```bash
   docker-compose ps
   ```

   DeberÃ­as ver:
   - `cassandra` (puerto 9042)
   - `clickhouse` (puertos 8123, 9000)
   - `jupyter` (puerto 8888)

4. **Acceder a Jupyter:**

   ```
   http://localhost:8888
   ```

---

## ğŸ“Š Fases del Proyecto

### Fase 1: ConfiguraciÃ³n del Entorno âœ“

- Despliegue de infraestructura con Docker Compose
- ConfiguraciÃ³n de redes y volÃºmenes
- CreaciÃ³n de esquemas en Cassandra y ClickHouse
- **ValidaciÃ³n:** Conectividad de Spark con Cassandra

### Fase 2: Ingesta Masiva de Datos ğŸ“¥

- GeneraciÃ³n de 100,000 registros de ventas sintÃ©ticas
- InserciÃ³n masiva en Cassandra (objetivo: < 5 minutos)
- **ValidaciÃ³n:** COUNT(\*) = 100,000 en `ventas_crudas`

### Fase 3: Procesamiento Paralelo ğŸ”„

- Lectura distribuida desde Cassandra
- Transformaciones con PySpark:
  - AgrupaciÃ³n por `fecha_venta` y `categoria`
  - CÃ¡lculo de ventas totales y cantidad de transacciones
  - Limpieza de datos (nulos/negativos)
- **ValidaciÃ³n:** DataFrame transformado correcto

### Fase 4: Carga y Consulta AnalÃ­tica ğŸ“ˆ

- Carga de datos agregados en ClickHouse
- Consultas analÃ­ticas:
  - Top 10 categorÃ­as por volumen
  - Promedio de ventas diarias por categorÃ­a
- **ValidaciÃ³n:** Consultas < 3 segundos

---

## ğŸ“ VersiÃ³n Recomendada de TecnologÃ­as

### Apache Cassandra

- **VersiÃ³n:** 4.x (recomendado: 4.1.x)
- **Imagen Docker:** `cassandra:4.1`
- **Modelo de datos:** Column-family (Wide-column)
- **CaracterÃ­sticas clave:**
  - Alta disponibilidad
  - Escalabilidad horizontal lineal
  - Optimizado para escrituras masivas
  - **Nota:** En laboratorio usar `SimpleStrategy` con `replication_factor=1`; en producciÃ³n usar `NetworkTopologyStrategy` con replicaciÃ³n â‰¥ 3

### Apache Spark

- **VersiÃ³n:** 3.x con PySpark (recomendado: 3.5.x)
- **Imagen Docker:** `jupyter/pyspark-notebook:latest` o `bitnami/spark:3.5`
- **CaracterÃ­sticas clave:**
  - Procesamiento distribuido en memoria
  - API de DataFrames para transformaciones
  - Conector nativo con Cassandra
  - **ConfiguraciÃ³n de paralelismo:** Ajustar particiones segÃºn `(cores Ã— 2-3)`, no usar default de 200 para datasets pequeÃ±os

### ClickHouse

- **VersiÃ³n:** 23.x o 24.x (recomendado: 24.1.x)
- **Imagen Docker:** `clickhouse/clickhouse-server:24.1`
- **Motor:** MergeTree con `ORDER BY (fecha_venta, categoria)`
- **CaracterÃ­sticas clave:**
  - Base de datos columnar
  - CompresiÃ³n de datos (10x-100x)
  - Optimizado para consultas analÃ­ticas (OLAP)
  - Tipos de datos: `Decimal(18,2)` para montos monetarios, `UInt32` para contadores

---

## ğŸ“ˆ MÃ©tricas de Rendimiento

### Criterios de Ã‰xito

| OperaciÃ³n                  | Objetivo     | Hardware MÃ­nimo  | Observaciones                                        |
| -------------------------- | ------------ | ---------------- | ---------------------------------------------------- |
| **Ingesta (Cassandra)**    | < 5 minutos  | 4 cores, 8GB RAM | Umbral conservador; tÃ­pico < 2 min con batch inserts |
| **TransformaciÃ³n (Spark)** | < 2 minutos  | 4 cores, 8GB RAM | Configurar particiones = cores Ã— 2-3                 |
| **Consulta Top 10**        | < 3 segundos | 4 cores, 8GB RAM | ClickHouse sobre 100k registros agregados            |
| **Consulta Promedio**      | < 3 segundos | 4 cores, 8GB RAM | AgregaciÃ³n temporal por categorÃ­a                    |

**Nota:** Los tiempos objetivo son conservadores. Documentar hardware real (CPU, RAM, SO) junto con mÃ©tricas medidas para comparaciÃ³n contextualizada.

---

## ğŸ› Troubleshooting

### Problema: Servicios no inician

```bash
# DiagnÃ³stico
docker-compose logs [servicio]
docker ps -a

# SoluciÃ³n
docker-compose down
docker-compose up -d
```

### Problema: Cassandra - Connection refused

**Causa:** Cassandra tarda 30-60 segundos en estar listo

```bash
# Verificar logs hasta ver:
docker logs cassandra-container | grep "Starting listening for CQL clients"
```

### Problema: Spark - OutOfMemoryError

**SoluciÃ³n:** Aumentar memoria en `docker-compose.yml`:

```yaml
jupyter:
  deploy:
    resources:
      limits:
        memory: 4G
```

### Problema: Dataset vacÃ­o en Spark

**Causa:** Nombres de keyspace/tabla incorrectos (case-sensitive)

```python
# Verificar nombres exactos
df = spark.read \
    .format("org.apache.spark.sql.cassandra") \
    .option("keyspace", "ventas_db") \
    .option("table", "ventas_crudas") \
    .load()

# Configurar particiones segÃºn cores disponibles
spark.conf.set("spark.sql.shuffle.partitions", "12")  # Ejemplo: 4 cores Ã— 3
```

### Problema: Puertos ocupados

```bash
# DiagnÃ³stico - Windows
netstat -ano | findstr :9042

# DiagnÃ³stico - Linux/Mac
ss -tulpn | grep 9042
# o
lsof -i :9042

# SoluciÃ³n: Cambiar puerto en docker-compose.yml
ports:
  - "9043:9042"  # Usar puerto local diferente
```

Ver [`Task.md`](Task.md) secciÃ³n "Troubleshooting" para mÃ¡s problemas comunes.

---

## ğŸ“š DocumentaciÃ³n

- **[Task.md](Task.md)** - Lista de tareas detallada con checklist completo
- **[NOTAS.md](NOTAS.md)** - Notas del proyecto y transcripciÃ³n original

### Comandos Ãštiles

```bash
# Ver logs en tiempo real
docker-compose logs -f [servicio]

# Conectar a Cassandra
docker exec -it cassandra-container cqlsh

# Conectar a ClickHouse
docker exec -it clickhouse-container clickhouse-client

# Verificar recursos
docker stats

# Detener servicios
docker-compose down
```

---

## Entregables

El proyecto requiere la entrega de un **documento PDF Ãºnico** que contenga:

1. **Diagrama de Arquitectura** - Flujo completo del pipeline
2. **CÃ³digo Fuente** - Scripts CQL, SQL, Python y docker-compose.yml
3. **Resultados y AnÃ¡lisis:**
   - Screenshots de validaciÃ³n (3 capturas mÃ­nimo)
   - CÃ³digo de consultas analÃ­ticas
   - AnÃ¡lisis comparativo Cassandra vs ClickHouse
4. **DocumentaciÃ³n de Problemas** - MÃ­nimo 2-3 problemas con formato estructurado

---

## ğŸ‘¥ Equipo

Este proyecto fue desarrollado para la asignatura **Sistemas de Bases de Datos II** de la UNEG.

| ğŸ­ Rol                    | ğŸ“‹ Responsabilidad                       | ğŸ‘¤ Integrante      |
| :------------------------ | :--------------------------------------- | :----------------- |
| **ğŸ—ï¸ Data Architect**     | Modelado, Pipelines Spark y ClickHouse   | **Jose Miserol**   |
| **ğŸ” Data Engineer**      | Ingesta Cassandra, ValidaciÃ³n y Pruebas  | **Miguel Gomez**   |
| **ğŸ“Š Analytics Engineer** | OptimizaciÃ³n OLAP y Consultas AnalÃ­ticas | **Anthony Medina** |

</div>

---

## Referencias

- [Apache Cassandra Documentation](https://cassandra.apache.org/)
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [ClickHouse Documentation](https://clickhouse.com/docs)
- [Docker Compose Reference](https://docs.docker.com/compose/)

---

## ğŸ“„ Licencia

Proyecto acadÃ©mico - UNEG 2025-II
