# Proyecto N¬∞ 2: Data Pipeline Escalable y Anal√≠tico

**Universidad:** UNEG - Universidad Nacional Experimental de Guayana  
**Asignatura:** Sistemas de Bases de Datos II  
**Semestre:** 2025-11  
**Profesora:** Clinia Cordero  
**Versi√≥n:** 0.0.7
**√öltima actualizaci√≥n:** 2026-01-21

---

## üìã Objetivo General

Dise√±ar, implementar y validar un prototipo funcional de arquitectura de datos escalable que simula la carga de grandes vol√∫menes de datos (NoSQL), su procesamiento distribuido (Paralelo) y su posterior almacenamiento anal√≠tico (Data Warehouse).

---

## üèóÔ∏è Arquitectura del Sistema

| Componente                   | Tecnolog√≠a             | Rol                                                                       |
| ---------------------------- | ---------------------- | ------------------------------------------------------------------------- |
| **Base de Datos NoSQL**      | Apache Cassandra       | Capa de Ingesta (OLTP) - Almacena datos crudos de transacciones           |
| **Procesamiento Paralelo**   | Apache Spark (PySpark) | Capa de Transformaci√≥n (ELT) - Procesa, limpia y agrega datos en paralelo |
| **Data Warehouse**           | ClickHouse             | Capa Anal√≠tica (OLAP) - Almacena datos agregados para informes            |
| **Plataforma de Despliegue** | Docker Compose         | Entorno de desarrollo unificado                                           |

---

## ‚öôÔ∏è Dependencias y Configuraci√≥n Cr√≠tica

### üö® IMPORTANTE: Conectores Spark

**Problema:** Apache Spark NO incluye nativamente los conectores para Cassandra ni ClickHouse. Sin esta configuraci√≥n, las **Fases 3 y 4 fallar√°n con `ClassNotFoundException`**.

#### Dependencias Requeridas

| Componente                    | Coordenada Maven                                    | Versi√≥n |
| ----------------------------- | --------------------------------------------------- | ------- |
| **Spark-Cassandra Connector** | `com.datastax.spark:spark-cassandra-connector_2.12` | 3.5.0   |
| **ClickHouse JDBC Driver**    | `com.clickhouse:clickhouse-jdbc`                    | 0.5.0   |

### Opci√≥n 1: Configuraci√≥n en docker-compose.yml (RECOMENDADO)

**Archivo:** `infra/docker-compose.yml`

```yaml
version: "3.8"

services:
  cassandra:
    image: cassandra:4.1.4 # ‚ö†Ô∏è Version pinning - NO usar :latest
    container_name: cassandra
    ports:
      - "9042:9042"
    environment:
      - CASSANDRA_CLUSTER_NAME=lab_cluster
      - CASSANDRA_DC=dc1
      - CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch
    volumes:
      - cassandra_data:/var/lib/cassandra
    healthcheck:
      test: ["CMD-SHELL", "cqlsh -e 'describe cluster'"]
      interval: 30s
      timeout: 10s
      retries: 5

  clickhouse:
    image: clickhouse/clickhouse-server:24.1.2 # ‚ö†Ô∏è Version pinning - NO usar :latest
    container_name: clickhouse
    ports:
      - "8123:8123" # HTTP
      - "9000:9000" # Native
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    ulimits:
      nofile:
        soft: 262144
        hard: 262144

  jupyter:
    image: jupyter/pyspark-notebook:spark-3.5.0 # ‚ö†Ô∏è CR√çTICO: Version pinning para estabilidad
    container_name: jupyter-spark
    user: "1000:100" # jovyan UID - evita problemas de permisos en Linux
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work/notebooks
      - ./src:/home/jovyan/work/src
      - ./infra:/home/jovyan/work/infra
    environment:
      - JUPYTER_ENABLE_LAB=yes
      # ‚ö†Ô∏è CR√çTICO: Configura los JARs necesarios
      - PYSPARK_SUBMIT_ARGS=--packages com.datastax.spark:spark-cassandra-connector_2.12:3.5.0,com.clickhouse:clickhouse-jdbc:0.5.0 pyspark-shell
    depends_on:
      cassandra:
        condition: service_healthy
      clickhouse:
        condition: service_started
    networks:
      - bigdata_net

networks:
  bigdata_net:
    driver: bridge

volumes:
  cassandra_data:
  clickhouse_data:
```

**Ventajas:**

- ‚úÖ Configuraci√≥n centralizada
- ‚úÖ JARs se descargan autom√°ticamente al iniciar
- ‚úÖ Funciona para todos los notebooks y scripts
- ‚úÖ Versiones inmutables garantizan estabilidad a largo plazo

**‚ö†Ô∏è Importante - Permisos en Linux:**
Si usas Linux y obtienes "Permission Denied" al guardar notebooks:

```bash
# Desde la carpeta del proyecto
sudo chown -R 1000:1000 notebooks/ src/ infra/
# El UID 1000 corresponde al usuario 'jovyan' dentro del contenedor
```

### Opci√≥n 2: Configuraci√≥n en SparkSession (C√≥digo)

**Ubicaci√≥n:** Al inicio de notebooks en Fases 3 y 4

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("Cassandra ETL") \
    .config("spark.jars.packages",
            "com.datastax.spark:spark-cassandra-connector_2.12:3.5.0,"
            "com.clickhouse:clickhouse-jdbc:0.5.0") \
    .config("spark.cassandra.connection.host", "cassandra") \
    .config("spark.cassandra.connection.port", "9042") \
    .config("spark.driver.memory", "2g") \
    .getOrCreate()
# ‚ö†Ô∏è IMPORTANTE: spark.driver.memory=2g evita OOM (deja espacio para Python/OS)
```

**Ventajas:**

- ‚úÖ Control fino por notebook
- ‚úÖ F√°cil de modificar versiones

**Desventajas:**

- ‚ö†Ô∏è Primera ejecuci√≥n tarda m√°s (descarga JARs)
- ‚ö†Ô∏è Debe repetirse en cada notebook

### Opci√≥n 3: Descarga Manual de JARs (NO RECOMENDADO)

```bash
# Desde terminal del contenedor Jupyter
cd /usr/local/spark/jars

# Spark-Cassandra Connector
wget https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector_2.12/3.5.0/spark-cassandra-connector_2.12-3.5.0.jar

# ClickHouse JDBC
wget https://repo1.maven.org/maven2/com/clickhouse/clickhouse-jdbc/0.5.0/clickhouse-jdbc-0.5.0-all.jar
```

**Solo usar si:**

- Las opciones 1 y 2 fallan
- No hay conexi√≥n a Maven Central

---

**Artefactos esperados por fase:**

- **Fase 1:** `infra/docker-compose.yml`, `infra/cassandra/schema.cql`, `infra/clickhouse/schema.sql`
- **Fase 2:** `src/generador_datos.py` o `notebooks/02_generador_datos.ipynb`
- **Fase 3:** `src/etl_spark.py` o `notebooks/03_etl_spark.ipynb`
- **Fase 4:** Consultas SQL documentadas en el notebook o en `docs/consultas_analiticas.sql`

---

## üìù Lista de Tareas

### Fase 1: Configuraci√≥n del Entorno y Arquitectura (Docker)

**Objetivo:** Levantar la infraestructura necesaria utilizando Docker Compose.

- [x] **1.1. Configuraci√≥n Local**
  - [x] **Instalar Docker seg√∫n sistema operativo:**
    - **Windows/Mac:** [Docker Desktop](https://www.docker.com/products/docker-desktop/) (incluye Docker Engine + Docker Compose)
    - **Linux:** [Docker Engine](https://docs.docker.com/engine/install/) + [Docker Compose](https://docs.docker.com/compose/install/)
  - [x] Crear carpeta de trabajo `proyecto_bigdata`
  - [x] Verificar requisitos del sistema:
    - M√≠nimo 8 GB RAM disponible
    - 20 GB espacio en disco
  - [ ] **Documentar entorno de desarrollo:**
    - [ ] Sistema operativo y versi√≥n
    - [ ] Modelo de CPU y n√∫mero de cores l√≥gicos
    - [ ] RAM total del sistema

- [x] **1.2. Configuraci√≥n YAML**
  - [x] Implementar archivo `docker-compose.yml` con los 3 servicios:
    - [x] Servicio Apache Cassandra
    - [x] Servicio ClickHouse
    - [x] Servicio Jupyter/Spark
  - [x] Configurar vol√∫menes para persistencia de datos
  - [x] Configurar redes entre contenedores

- [x] **1.3. Despliegue**
  - [x] Ejecutar `docker-compose up -d`
  - [x] Verificar que todos los contenedores est√©n corriendo
  - [x] Revisar logs de cada servicio

- [x] **1.4. Validaci√≥n de Conectividad**
  - [x] Acceder a Jupyter en `http://localhost:8888`
  - [x] Ejecutar "Hola Mundo" de PySpark
  - [x] Confirmar que el conector de Cassandra funciona
  - [ ] **üì∏ Captura requerida:** Screenshot de validaci√≥n PySpark

- [x] **1.5. Configuraci√≥n de Esquemas**
  - [x] **Cassandra:** Crear Keyspace

    ```cql
    CREATE KEYSPACE IF NOT EXISTS ventas_db
    WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};
    ```

    - [ ] **Nota de configuraci√≥n:**
      - [ ] `SimpleStrategy` con `replication_factor=1` es **solo para entorno de laboratorio**
      - [ ] En producci√≥n: `NetworkTopologyStrategy` con replicaci√≥n ‚â• 3
      - [ ] **Seguridad:** Para laboratorio se usa usuario por defecto; en producci√≥n configurar autenticaci√≥n (`cassandra.yaml`: `authenticator: PasswordAuthenticator`)

  - [x] **Cassandra:** Ejecutar script CQL para crear tabla `ventas_crudas` (`infra/cassandra/schema.cql`):
    - [ ] `id_venta` (UUID)
    - [ ] `fecha_venta` (Date/Timestamp) - **Partition Key**
    - [ ] `id_producto` (Text)
    - [ ] `categoria` (Text)
    - [ ] `monto_total` (Decimal)
    - [ ] `id_cliente` (Text)
    - [ ] **Nota de dise√±o:** En producci√≥n se recomienda composite partition key `(fecha_venta, categoria)` para mejor distribuci√≥n; para este laboratorio se usa solo `fecha_venta` por simplicidad
  - [x] **ClickHouse:** Crear base de datos `dw_analitico`
    ```sql
    CREATE DATABASE IF NOT EXISTS dw_analitico;
    ```
  - [x] **ClickHouse:** Crear tabla `ventas_resumen` en ClickHouse (`infra/clickhouse/schema.sql`) con:
    - [ ] `fecha_venta` (Date)
    - [ ] `categoria` (String)
    - [ ] `ventas_totales` (Decimal(18,2))
    - [ ] `cantidad_transacciones` (UInt32)
    - [ ] **Engine especificado:** `ENGINE = MergeTree() ORDER BY (fecha_venta, categoria)`
    - [ ] Ejemplo completo:

      ```sql
      CREATE TABLE IF NOT EXISTS dw_analitico.ventas_resumen (
          fecha_venta Date,
          categoria String,
          ventas_totales Decimal(18,2),
          cantidad_transacciones UInt32
      ) ENGINE = ReplacingMergeTree()  -- ‚ö†Ô∏è Deduplica autom√°ticamente en re-ejecuciones
      ORDER BY (fecha_venta, categoria);

      -- ALTERNATIVA: MergeTree() si usas mode("overwrite") en Spark
      -- ReplacingMergeTree() es m√°s robusto para idempotencia
      ```

---

### Fase 2: Ingesta Masiva de Datos (NoSQL - Cassandra)

**Objetivo:** Simular proceso de ingesta de datos transaccionales en Cassandra.

- [x] **2.1. Generador de Datos**
  - [x] **‚ö†Ô∏è IMPORTANTE - Ubicaci√≥n de Ejecuci√≥n:**
    - [x] **OBLIGATORIO:** Ejecutar DENTRO del contenedor Jupyter
    - [x] **RAZ√ìN:** Resoluci√≥n DNS - `cassandra` solo funciona en red Docker interna
    - [x] ‚ùå NO ejecutar desde IDE local (fallar√° con error de conexi√≥n)
  - [x] **Elegir formato de implementaci√≥n:**
    - [x] Opci√≥n A (Recomendado): Notebook `notebooks/02_generador_datos.ipynb`
    - [ ] Opci√≥n B: Script Python `src/generador_datos.py` (ejecutar desde terminal Jupyter)
  - [x] **Gesti√≥n de archivos:**
    - [x] La opci√≥n elegida ser√° la **fuente de verdad oficial** para evaluaci√≥n
    - [x] Si se mantienen ambos archivos, marcar el no usado como `LEGACY_` en el nombre
    - [x] Ejemplo: Si se usa notebook, renombrar script a `LEGACY_generador_datos.py`
  - [x] **Instalar dependencias en Jupyter:**
    ```bash
    # Desde terminal Jupyter
    pip install cassandra-driver
    ```
  - [x] Implementar generaci√≥n de 100,000 registros
  - [x] Implementar generaci√≥n aleatoria de:
    - [x] `id_venta` (√∫nico)
    - [x] `fecha_venta` (rango de fechas realista)
    - [x] `id_producto` (variedad de productos)
    - [x] `categoria` (Electr√≥nica, Ropa, Alimentos, etc.)
    - [x] `monto_total` (valores monetarios realistas)
    - [x] `id_cliente` (pool de clientes)
  - [x] Validar formato de datos generados

- [x] **2.2. Inserci√≥n Masiva**
  - [x] Instalar `cassandra-driver` en Python
  - [x] Configurar conexi√≥n a Cassandra desde Jupyter
  - [x] Implementar batch inserts para optimizar rendimiento (batches de 100-500 registros)
  - [x] Insertar los 100,000 registros en `ventas_crudas`
  - [x] **Criterio de rendimiento:** Objetivo insertar 100,000 registros en < 5 minutos
    - [x] **Nota:** Este es un umbral conservador para m√°quinas de bajos recursos; en entornos t√≠picos deber√≠a ser < 2 minutos
    - [x] **Tiempo logrado:** ~6.39 segundos (15,642 regs/seg) - Muy por debajo del objetivo
    - [ ] **Si tiempo es significativamente mayor (> 7 min):** Explicar limitaciones del entorno y optimizaciones intentadas
  - [x] Medir y documentar:
    - [x] Tiempo de inserci√≥n total: **6.39 segundos**
    - [ ] Hardware del host (CPU, RAM, SO)

- [x] **2.3. Validaci√≥n de Ingesta**
  - [x] Conectar v√≠a `cqlsh` al contenedor Cassandra
  - [x] Ejecutar `SELECT COUNT(*) FROM ventas_crudas;`
  - [x] Verificar que existen 100,000 registros (**Resultado: 228,657 registros**)
  - [x] Ejecutar consultas de muestra para validar datos
  - [ ] **üì∏ Captura requerida:** Screenshot mostrando COUNT(\*) = 100,000

---

### Fase 3: Procesamiento Paralelo y Transformaci√≥n (Spark)

**Objetivo:** Implementar l√≥gica de negocio usando PySpark para transformar datos crudos en datos anal√≠ticos.

- [x] **3.1. Lectura Distribuida**
  - [x] **Elegir formato de implementaci√≥n (consistente con Fase 2):**
    - [x] Opci√≥n A: Notebook `notebooks/03_etl_spark.ipynb`
    - [ ] Opci√≥n B: Script `src/etl_spark.py`
  - [x] **Gesti√≥n de archivos:**
    - [x] La opci√≥n elegida ser√° la **fuente de verdad oficial** para evaluaci√≥n
    - [ ] Si se mantienen ambos, marcar el no usado como `LEGACY_` en el nombre
  - [x] Configurar SparkSession con conector Cassandra
    - [x] **Opci√≥n:** Usar configuraci√≥n de docker-compose.yml (Recomendado - ya tiene JARs)
    - [ ] **O alternativamente:** Configurar JARs en c√≥digo (ver secci√≥n "Dependencias y Configuraci√≥n Cr√≠tica")
    - [x] Ejemplo m√≠nimo:

      ```python
      from pyspark.sql import SparkSession

      # Si usas docker-compose.yml, los JARs ya est√°n configurados
      spark = SparkSession.builder \
          .appName("Cassandra ETL") \
          .config("spark.cassandra.connection.host", "cassandra") \
          .config("spark.driver.memory", "2g") \
          .getOrCreate()
      # Nota: spark.driver.memory=2g evita OOM killer
      ```

  - [ ] **Configurar paralelismo de Spark:**
    - [ ] Ajustar n√∫mero de particiones seg√∫n: (n√∫mero de cores) √ó (2-3)
    - [ ] Para dataset de 100k registros, evitar usar default de 200 particiones
    - [ ] Ejemplo: 4 cores ‚Üí configurar 8-12 particiones
  - [x] Leer datos de tabla `ventas_crudas`
  - [x] Especificar `fecha_venta` como Partition Key para lectura paralela
  - [x] Verificar que los datos se carguen correctamente en DataFrame

- [x] **3.2. L√≥gica de Transformaci√≥n**
  - [x] Implementar agrupaci√≥n por `fecha_venta` y `categoria`
  - [x] Calcular suma de `monto_total` (Ventas Totales por Categor√≠a)
  - [x] Calcular conteo de `id_venta` (Cantidad de Transacciones)
  - [x] Crear DataFrame resultante con columnas:
    - [x] `fecha_venta`
    - [x] `categoria`
    - [x] `ventas_totales`
    - [x] `cantidad_transacciones`
  - [x] **Definir esquema expl√≠cito con DecimalType (RECOMENDADO):**
    - [ ] **RAZ√ìN:** Spark infiere `Double` por defecto, no `Decimal` preciso
    - [ ] Ejemplo completo:

      ```python
      from pyspark.sql.types import StructType, StructField, DateType, StringType, DecimalType, IntegerType

      # Esquema para ventas_resumen
      schema_resumen = StructType([
          StructField("fecha_venta", DateType(), False),
          StructField("categoria", StringType(), False),
          StructField("ventas_totales", DecimalType(18, 2), False),  # ‚úÖ Precisi√≥n monetaria
          StructField("cantidad_transacciones", IntegerType(), False)
      ])

      # Aplicar al crear DataFrame
      df_resumen = df_agrupado.select(
          col("fecha_venta").cast(DateType()),
          col("categoria"),
          col("ventas_totales").cast(DecimalType(18, 2)),
          col("cantidad_transacciones").cast(IntegerType())
      )
      ```

- [ ] **3.3. Limpieza de Datos (Opcional pero Recomendado)**
  - [ ] Implementar filtro para eliminar registros con `monto_total` nulo
  - [ ] Implementar filtro para eliminar registros con `monto_total` negativo
  - [ ] **Documentaci√≥n obligatoria:**
    - [ ] N√∫mero de registros descartados
    - [ ] Porcentaje sobre el total original (ej. "150 registros / 0.15%")
    - [ ] Raz√≥n de descarte por categor√≠a (nulos vs negativos)

---

### Fase 4: Carga y Consulta Anal√≠tica (Data Warehouse)

**Objetivo:** Cargar datos transformados a ClickHouse y demostrar potencial anal√≠tico.

- [x] **4.1. Carga (ELT)**
  - [x] **‚ö†Ô∏è IMPORTANTE - Idempotencia:**
    - [x] **Opci√≥n A (Recomendado):** Usar `ReplacingMergeTree` en ClickHouse (ya configurado en schema)
      - Deduplica autom√°ticamente por ORDER BY key
      - Permite re-ejecutar el pipeline sin duplicados
  - [x] Configurar conector PySpark-ClickHouse
  - [x] Escribir DataFrame resultante en `dw_analitico.ventas_resumen`
  - [x] Verificar modo de escritura (append/overwrite)

- [x] **4.2. Validaci√≥n Anal√≠tica**
  - [x] Conectarse al cliente ClickHouse
  - [x] **Consulta Anal√≠tica 1:** Top 10 categor√≠as con mayor volumen de ventas
    ```sql
    -- Implementar consulta que muestre las 10 categor√≠as con
    -- mayor volumen de ventas en todo el per√≠odo
    ```
  - [x] **Consulta Anal√≠tica 2:** Promedio de ventas diarias por categor√≠a
    ```sql
    -- Implementar consulta que calcule el promedio de
    -- ventas diarias por categor√≠a
    ```
  - [ ] Ejecutar ambas consultas y documentar resultados
  - [ ] **üì∏ Capturas requeridas:** Screenshots de resultados de ambas consultas
  - [x] **Obligatorio:** Exportar consultas a `docs/consultas_analiticas.sql` (incluso si se ejecutaron en notebook)

- [ ] **4.3. Informe de Rendimiento**
  - [ ] Documentar tiempo de ejecuci√≥n de ingesta (Fase 2)
  - [ ] Documentar tiempo de ejecuci√≥n de consultas anal√≠ticas (Fase 4.2)
  - [ ] **Criterio de rendimiento:** Las consultas anal√≠ticas deben ejecutarse en < 3 segundos para el dataset de 100,000 registros
    - [ ] **Si no se alcanza el objetivo:** Documentar expl√≠citamente limitaciones del entorno y optimizaciones intentadas
  - [ ] Comparar tiempos y analizar eficiencia
  - [ ] Crear tabla comparativa (incluir hardware para contexto):
        | Operaci√≥n | Tiempo medido | Hardware (CPU/RAM/SO) | Observaciones |
        |-----------|---------------|----------------------|---------------|
        | Ingesta Cassandra | X min Y seg | CPU: ..., RAM: ..., SO: ... | |
        | Transformaci√≥n Spark | Z seg | CPU: ..., RAM: ..., SO: ... | |
        | Consulta 1 ClickHouse | W seg | CPU: ..., RAM: ..., SO: ... | |
        | Consulta 2 ClickHouse | V seg | CPU: ..., RAM: ..., SO: ... | |

---

## üì¶ Entrega Final del Proyecto

**Formato:** Documento √∫nico en PDF v√≠a Ungevirtual  
**Integrantes:** 3 por equipo

### Contenido del Documento

- [ ] **1. Diagrama de Arquitectura**
  - [ ] Crear diagrama de bloques mostrando flujo:
    - Cassandra ‚Üí Spark ‚Üí ClickHouse
  - [ ] Incluir etiquetas de tecnolog√≠as
  - [ ] Mostrar tipo de capa (OLTP, ELT, OLAP)

- [ ] **2. C√≥digo Fuente**
  - [ ] Adjuntar `docker-compose.yml` completo
  - [ ] Adjuntar script generador de datos (Python)
  - [ ] Adjuntar script Spark ETL (PySpark)
  - [ ] Adjuntar scripts SQL/CQL (esquemas y consultas)
  - [ ] Incluir comentarios explicativos en el c√≥digo

- [ ] **3. Resultados y An√°lisis**
  - [ ] **Captura 1:** Validaci√≥n de conectividad PySpark (Fase 1.4)
  - [ ] **Captura 2:** 100,000 registros en Cassandra (Fase 2.3)
  - [ ] **Consultas:** C√≥digo de las 2 consultas anal√≠ticas ClickHouse (Fase 4.2)
  - [ ] **An√°lisis Cassandra:** Explicar por qu√© Cassandra fue la elecci√≥n correcta para ingesta
    - [ ] Mencionar arquitectura distribuida
    - [ ] Mencionar escalabilidad horizontal
    - [ ] Mencionar optimizaci√≥n para escrituras
  - [ ] **An√°lisis ClickHouse:** Explicar por qu√© ClickHouse es superior para consultas anal√≠ticas
    - [ ] Mencionar arquitectura columnar
    - [ ] Mencionar optimizaci√≥n para lecturas agregadas
    - [ ] Mencionar compresi√≥n de datos

- [ ] **4. Documentaci√≥n Adicional**
  - [ ] Incluir instrucciones de ejecuci√≥n paso a paso
    - [ ] **Recomendado:** Centralizar en `README.md` del proyecto (ver estructura en secci√≥n "Estructura del Proyecto")
  - [ ] **Documentar problemas encontrados (m√≠nimo 2-3) en formato estructurado:**
    - [ ] Problema 1:
      - S√≠ntoma/Error (mensaje exacto)
      - Comando de diagn√≥stico usado
      - Soluci√≥n aplicada
    - [ ] Problema 2:
      - S√≠ntoma/Error (mensaje exacto)
      - Comando de diagn√≥stico usado
      - Soluci√≥n aplicada
    - [ ] Problema 3 (si aplica):
      - S√≠ntoma/Error (mensaje exacto)
      - Comando de diagn√≥stico usado
      - Soluci√≥n aplicada
  - [ ] Conclusiones del equipo sobre cada tecnolog√≠a

---

## üìå Notas T√©cnicas

### Comandos √ötiles

```bash
# Iniciar servicios
docker-compose up -d

# Ver logs
docker-compose logs -f [servicio]

# Conectar a Cassandra
docker exec -it [cassandra-container] cqlsh

# Conectar a ClickHouse
docker exec -it [clickhouse-container] clickhouse-client

# Detener servicios
docker-compose down
```

### Consideraciones de Dise√±o

#### Cassandra - Modelado de Datos

- **Partition Key recomendada:** En producci√≥n, usar composite partition key `(fecha_venta, categoria)` para mejorar distribuci√≥n en escenarios reales con grandes vol√∫menes
- **Para este laboratorio:** Se usa solo `fecha_venta` por simplicidad did√°ctica
- **Justificaci√≥n:** La distribuci√≥n por fecha permite lectura paralela eficiente en Spark y evita hot spots si las fechas est√°n bien distribuidas

#### Cassandra - Ingesta

- **Batch Inserts:** Agrupar inserts en batches de 100-500 registros para mejor rendimiento
- **Driver:** Usar `cassandra-driver` con prepared statements para optimizar

#### Spark - Procesamiento

- **Spark Parallelism:** Ajustar n√∫mero de particiones seg√∫n: `(n√∫mero de cores) √ó (2-3)`
  - **Evitar usar el default ciegamente** (200 particiones): para datasets peque√±os como 100k registros, esto genera overhead innecesario
  - Ejemplo: En m√°quina con 4 cores, configurar 8-12 particiones
- **Lectura optimizada:** Especificar partition key en la lectura de Cassandra para pushdown

#### ClickHouse - Almacenamiento Anal√≠tico

- **Engine:** `ReplacingMergeTree() ORDER BY (fecha_venta, categoria)` para idempotencia y mejor rendimiento
  - `ReplacingMergeTree` deduplica autom√°ticamente por ORDER BY key
  - Alternativa: `MergeTree()` si se usa `.mode("overwrite")` en Spark
- **Ordenamiento:** El ORDER BY permite queries eficientes por rango de fechas y categor√≠as
- **Compresi√≥n:** ClickHouse comprime autom√°ticamente datos columnares (t√≠picamente 10x-100x)

### Troubleshooting: Problemas T√≠picos

#### Problema 1: Servicios no inician o puertos ocupados

**Diagn√≥stico:**

```bash
# Verificar estado de contenedores
docker ps -a

# Ver logs de un servicio espec√≠fico
docker-compose logs cassandra
docker-compose logs clickhouse
docker-compose logs jupyter

# Verificar puertos ocupados
# Windows:
netstat -ano | findstr :9042    # Cassandra
netstat -ano | findstr :9000    # ClickHouse
netstat -ano | findstr :8888    # Jupyter

# Linux/Mac:
ss -tulpn | grep 9042           # Cassandra
ss -tulpn | grep 9000           # ClickHouse
ss -tulpn | grep 8888           # Jupyter
# o alternativamente:
lsof -i :9042
```

**Soluciones:**

- Si el puerto est√° ocupado, cambiar el mapeo en `docker-compose.yml`:
  ```yaml
  ports:
    - "9043:9042" # Usar puerto local diferente
  ```
- Si el contenedor fall√≥ al iniciar, revisar logs y reintentar:
  ```bash
  docker-compose down
  docker-compose up -d
  ```

#### Problema 2: Falta de memoria en contenedor Spark

**S√≠ntomas:**

- Jupyter kernel muere durante procesamiento
- Error: `OutOfMemoryError: Java heap space`

**Diagn√≥stico:**

```bash
# Verificar uso de recursos
docker stats

# Ver logs de Spark
docker-compose logs jupyter | grep -i memory
```

**Soluci√≥n:**
Aumentar memoria del contenedor en `docker-compose.yml`:

```yaml
services:
  jupyter:
    # ... otras configuraciones
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
    # Nota: deploy.resources solo aplica en Docker Swarm mode;
    # para Docker Compose est√°ndar es orientativo. Alternativamente:
    mem_limit: 4g
    mem_reservation: 2g
```

#### Problema 3: Error de conexi√≥n con Cassandra

**S√≠ntomas:**

- `NoHostAvailable: ('Unable to connect to any servers')`
- Timeout al intentar conectar desde Python

**Diagn√≥stico:**

```bash
# Verificar que Cassandra est√© completamente iniciado
docker logs [cassandra-container] | grep "Starting listening for CQL clients"

# Intentar conexi√≥n manual
docker exec -it [cassandra-container] cqlsh

# Verificar red Docker (el nombre var√≠a seg√∫n carpeta del proyecto)
docker network ls
docker network inspect <nombre_de_red>  # T√≠picamente: <carpeta>_default
```

**Soluciones:**

- Cassandra tarda 30-60 segundos en estar listo; esperar mensaje en logs
- Verificar nombre del contenedor en c√≥digo Python:
  ```python
  from cassandra.cluster import Cluster
  cluster = Cluster(['cassandra'])  # Usar nombre del servicio, no 'localhost'
  ```
- Si persiste, reiniciar contenedor:
  ```bash
  docker-compose restart cassandra
  ```

#### Problema 4: Error de conexi√≥n con ClickHouse

**S√≠ntomas:**

- `Network error: Connection refused`
- No se pueden ejecutar consultas desde PySpark

**Diagn√≥stico:**

```bash
# Verificar que ClickHouse est√© corriendo
docker exec -it [clickhouse-container] clickhouse-client

# Verificar conectividad desde Jupyter
docker exec -it [jupyter-container] ping clickhouse

# Ver logs
docker logs [clickhouse-container]
```

**Soluciones:**

- Verificar que el puerto 9000 (protocolo nativo) est√© mapeado
- Usar nombre de servicio en conexi√≥n, no IP:
  ```python
  clickhouse_host = "clickhouse"  # No usar 'localhost'
  ```

#### Problema 5: ClassNotFoundException - Conector Cassandra/ClickHouse

**S√≠ntomas:**

- Error al ejecutar `spark.read.format("org.apache.spark.sql.cassandra")`
- Mensaje completo:
  ```
  java.lang.ClassNotFoundException: org.apache.spark.sql.cassandra.DefaultSource
  ```
- O similar para ClickHouse JDBC

**Diagn√≥stico:**

```python
# El error ocurre en esta l√≠nea:
df = spark.read.format("org.apache.spark.sql.cassandra").load()
```

**Causa:**

- ‚ö†Ô∏è **CR√çTICO:** Faltan los JARs de los conectores
- Spark NO incluye estos conectores nativamente
- Sin configurarlos, las Fases 3 y 4 son INOPERABLES

**Soluci√≥n:**

1. Ver secci√≥n **"‚öôÔ∏è Dependencias y Configuraci√≥n Cr√≠tica"** al inicio del documento
2. Implementar Opci√≥n 1 (docker-compose.yml) o Opci√≥n 2 (SparkSession)
3. Reiniciar kernel de Jupyter despu√©s de configurar

**Verificaci√≥n:**

```python
# Despu√©s de configurar, esto NO debe dar error:
spark = SparkSession.builder \
    .appName("Test") \
    .config("spark.jars.packages",
            "com.datastax.spark:spark-cassandra-connector_2.12:3.5.0") \
    .getOrCreate()

# Verificar que el conector est√© disponible
spark.sparkContext._jsc.sc().listJars()  # Debe aparecer cassandra-connector
```

#### Problema 6: Dataset vac√≠o en Spark al leer de Cassandra

**S√≠ntomas:**

- `df.count()` retorna 0
- No se leen datos aunque existan en Cassandra

**Diagn√≥stico:**

```python
# Verificar configuraci√≥n del conector
df = spark.read \
    .format("org.apache.spark.sql.cassandra") \
    .option("keyspace", "ventas_db") \
    .option("table", "ventas_crudas") \
    .load()

print(f"Conteo: {df.count()}")
df.printSchema()

# Verificar datos en Cassandra directamente
# docker exec -it cassandra-container cqlsh
# SELECT COUNT(*) FROM ventas_db.ventas_crudas;
```

**Soluciones:**

- Verificar nombres exactos de keyspace y tabla (case-sensitive)
- Confirmar que el conector Cassandra-Spark est√© instalado
- Verificar versi√≥n de compatibilidad entre Spark y Cassandra

#### Problema 7: Error al escribir en ClickHouse desde Spark

**S√≠ntomas:**

- `JDBC connection failed`
- Timeout al escribir DataFrame

**Diagn√≥stico:**

```python
# Verificar string de conexi√≥n JDBC
jdbc_url = "jdbc:clickhouse://clickhouse:8123/dw_analitico"

# Test de conexi√≥n simple
df_test = spark.createDataFrame([(1, "test")], ["id", "value"])
df_test.write \
    .format("jdbc") \
    .option("url", jdbc_url) \
    .option("dbtable", "test_table") \
    .mode("overwrite") \
    .save()
```

**Soluciones:**

- Usar puerto HTTP (8123) para JDBC, no puerto nativo (9000)
- Instalar driver JDBC de ClickHouse en Spark
- Verificar permisos de usuario en ClickHouse

---

## ‚úÖ Criterios de √âxito

- [ ] Todos los servicios Docker funcionando correctamente
- [ ] 100,000 registros insertados exitosamente en Cassandra
- [ ] Transformaci√≥n Spark ejecutada sin errores
- [ ] Datos cargados correctamente en ClickHouse
- [ ] Consultas anal√≠ticas funcionando y retornando resultados
- [ ] Documentaci√≥n completa con todas las capturas requeridas
- [ ] An√°lisis comparativo Cassandra vs ClickHouse bien fundamentado
- [ ] Hardware documentado para contextualizar m√©tricas de rendimiento
- [ ] Archivos legacy claramente marcados (si aplica)

---

## üîí Consideraciones de Seguridad (Informativas)

**Nota:** Este proyecto usa configuraci√≥n de laboratorio. Para entornos de producci√≥n considerar:

### Cassandra

- Habilitar autenticaci√≥n: `authenticator: PasswordAuthenticator` en `cassandra.yaml`
- Cambiar credenciales por defecto (usuario: `cassandra`, password: `cassandra`)
- Habilitar SSL/TLS para conexiones cliente-servidor
- Configurar `authorizer: CassandraAuthorizer` para control de acceso

### ClickHouse

- Configurar usuarios y passwords en `users.xml`
- No exponer puerto 9000 (nativo) fuera del host en producci√≥n
- Usar perfiles de usuario para limitar recursos
- Habilitar SSL para conexiones HTTP

### Docker

- **Puertos expuestos:** En laboratorio se mapean a `0.0.0.0`; en producci√≥n limitar a `127.0.0.1:puerto`
- Ejemplo seguro: `127.0.0.1:9042:9042` en lugar de `9042:9042`
- Usar Docker secrets para credenciales en lugar de variables de entorno
- Definir networks aisladas entre servicios

**Para este laboratorio:** Usar configuraci√≥n por defecto est√° bien; solo tener conciencia de que no es production-ready.

---

## üìù Changelog

### v0.0.7 (2026-01-21) - Calidad Industrial (Staff Engineer)

**Nivel de madurez:** Functional Prototype ‚Üí Resilient Pipeline

**üîí Version Pinning (Inmutabilidad):**

- Changed: `cassandra:4.1` ‚Üí `cassandra:4.1.4`
- Changed: `clickhouse-server:24.1` ‚Üí `clickhouse-server:24.1.2`
- Changed: `jupyter/pyspark-notebook:latest` ‚Üí `jupyter/pyspark-notebook:spark-3.5.0`
- **RAZ√ìN:** `:latest` rompe el laboratorio cuando cambian versiones de Spark/Scala

**‚ö° Gesti√≥n de Recursos (OOM Prevention):**

- Added: `.config("spark.driver.memory", "2g")` en todos los snippets de SparkSession
- **RAZ√ìN:** Evita que el contenedor muera por OOM cuando Spark consume toda la memoria

**‚ôªÔ∏è Idempotencia del Pipeline:**

- Changed: Engine ClickHouse de `MergeTree()` ‚Üí `ReplacingMergeTree()`
- Added: Secci√≥n de idempotencia en Fase 4.1 con dos estrategias
- **RAZ√ìN:** Re-ejecutar el notebook NO duplica datos (problema cr√≠tico de Data Engineering)

**üêß Permisos Linux:**

- Added: `user: "1000:100"` en servicio Jupyter (UID jovyan)
- Added: Instrucciones de `chown` para resolver Permission Denied
- **RAZ√ìN:** Evita frustraci√≥n de estudiantes en Linux con problemas de permisos

**Impacto:** Pipeline ahora es reproducible, idempotente y estable a largo plazo.

### v0.0.5 (2026-01-21) - Correcci√≥n de Bloqueadores Cr√≠ticos

**üö® BLOQUEADORES RESUELTOS (Auditor√≠a de Ingenier√≠a):**

- Added: **Secci√≥n completa "Dependencias y Configuraci√≥n Cr√≠tica"** (130+ l√≠neas)
  - Tabla de coordenadas Maven para Spark-Cassandra Connector y ClickHouse JDBC
  - docker-compose.yml FUNCIONAL completo con:
    - Vol√∫menes para persistencia (notebooks/, src/, infra/)
    - PYSPARK_SUBMIT_ARGS con JARs pre-configurados
    - Healthchecks para Cassandra
    - Networks aisladas
  - 3 opciones de configuraci√≥n (docker-compose, SparkSession, manual)
  - C√≥digo de ejemplo completo para SparkSession

**Estandarizaci√≥n de ejecuci√≥n:**

- Added: Advertencia OBLIGATORIA de ejecutar en contenedor Jupyter
- Added: Explicaci√≥n de problema DNS (cassandra vs localhost)
- Added: Requisito de instalaci√≥n de cassandra-driver
- Fixed: Ambig√ºedad eliminada - TODO se ejecuta en Jupyter

**Precisi√≥n de datos:**

- Added: Gu√≠a completa de esquema Decimal expl√≠cito con DecimalType(18,2)
- Added: C√≥digo de ejemplo de StructType completo para ventas_resumen
- Added: Explicaci√≥n de por qu√© Spark infiere Double por defecto

**Troubleshooting ampliado:**

- Added: **Problema 5: ClassNotFoundException** (CR√çTICO)
  - S√≠ntomas exactos del error
  - Diagn√≥stico con c√≥digo
  - Soluci√≥n con referencias a secci√≥n de Dependencias
  - Verificaci√≥n post-configuraci√≥n
- Renumerados problemas posteriores (5‚Üí6, 6‚Üí7)

**Impacto:** Sin estas correcciones, Fases 3 y 4 eran 100% INOPERABLES. Ahora el proyecto es completamente ejecutable.

### v0.0.4 (2026-01-21) - Refinamiento Cr√≠tico

**Consideraciones de seguridad a√±adidas:**

- Added: Secci√≥n completa "Consideraciones de Seguridad" con buenas pr√°cticas para producci√≥n
- Added: Notas sobre autenticaci√≥n en Cassandra y ClickHouse
- Added: Advertencias sobre exposici√≥n de puertos Docker (0.0.0.0 vs 127.0.0.1)
- Added: Menci√≥n de Docker secrets para credenciales

**Clarificaciones Docker/Compose:**

- Fixed: Aclaraci√≥n sobre `deploy.resources` (solo Swarm) vs `mem_limit` (Compose est√°ndar)
- Enhanced: Nombre de red Docker explicado como variable seg√∫n nombre de carpeta del proyecto
- Added: Comando `docker network ls` para identificar nombre correcto

**Manejo de expectativas de rendimiento:**

- Added: Criterio expl√≠cito para cuando NO se alcanzan objetivos (documentar limitaciones)
- Enhanced: Gu√≠a bidireccional: qu√© hacer si tiempo es menor O mayor que objetivo
- Added: Umbrales espec√≠ficos (< 1 min = superior, > 7 min = explicar)

**Gesti√≥n de archivos y fuente de verdad:**

- Added: Convenci√≥n `LEGACY_` para marcar archivos no oficiales
- Enhanced: Clarificaci√≥n de cu√°l ser√° evaluado y por qu√©
- Added: Ejemplo concreto de renombrado

**Referencias cruzadas:**

- Added: Referencia expl√≠cita a `README.md` como lugar recomendado para instrucciones de ejecuci√≥n
- Enhanced: Conexi√≥n entre estructura de proyecto y documentaci√≥n adicional

**Criterios de √©xito ampliados:**

- Added: Hardware documentado como criterio
- Added: Archivos legacy marcados como criterio

### v0.0.3 (2026-01-21) - Pulido de Ingenier√≠a

**Claridad multiplataforma:**

- Added: Instrucciones espec√≠ficas para Docker Engine (Linux) vs Docker Desktop (Windows/Mac)
- Added: Comandos de diagn√≥stico multiplataforma (netstat para Windows, ss/lsof para Linux/Mac)
- Added: Links directos a instalaci√≥n de Docker seg√∫n plataforma

**Especificaciones t√©cnicas mejoradas:**

- Fixed: Tipo de dato ClickHouse de `Decimal128(2)` a `Decimal(18,2)` (m√°s apropiado para montos monetarios)
- Added: Nota expl√≠cita sobre `SimpleStrategy` solo para laboratorio, recomendar `NetworkTopologyStrategy` en producci√≥n
- Enhanced: Gu√≠a de paralelismo Spark con f√≥rmula `(cores √ó 2-3)` en lugar de default ciego de 200 particiones

**Consistencia y fuente de verdad:**

- Added: Directriz para elegir UNA fuente de verdad entre notebooks y scripts
- Added: Requisito obligatorio de exportar consultas SQL a `docs/consultas_analiticas.sql`
- Added: Clarificaci√≥n de qu√© opci√≥n ser√° la evaluada

**Contextualizaci√≥n de rendimiento:**

- Enhanced: Criterio de < 5 min explicado como umbral conservador (t√≠pico deber√≠a ser < 2 min)
- Added: Requisito de documentar hardware (CPU, RAM, SO) junto con m√©tricas de tiempo
- Enhanced: Tabla comparativa de rendimiento incluye columna de hardware para contexto

**Documentaci√≥n del entorno:**

- Added: Checklist de documentar SO, CPU (modelo y cores), RAM total
- Added: Requisito de documentar si tiempo mejora significativamente el objetivo

**Mejoras de forma:**

- Fixed: Emojis rotos en encabezados (üìÅ, üìù)
- Enhanced: Comentarios inline en c√≥digo SQL para claridad

### v0.0.2 (2026-01-21) - Rigor de Ingenier√≠a

- Added: Estructura completa del proyecto con carpetas y artefactos esperados
- Enhanced: Modelado de datos con especificaciones SQL/CQL completas
- Added: Criterios cuantitativos de rendimiento (5 min ingesta, 3 seg consultas)
- Enhanced: Documentaci√≥n de problemas con formato estructurado obligatorio
- Added: Secci√≥n troubleshooting con 6 problemas comunes documentados
- Enhanced: Consideraciones de dise√±o organizadas por tecnolog√≠a
- Added: Metadatos de versi√≥n y fecha de actualizaci√≥n

### v0.0.1 (2026-01-21) - Versi√≥n Inicial

- Versi√≥n inicial basada en el enunciado del proyecto oficial
- Estructura de 4 fases con checklists detallados
- Requisitos t√©cnicos y entregables definidos

---

**Fecha de creaci√≥n:** 2026-01-21  
**√öltima actualizaci√≥n:** 2026-01-21  
**Versi√≥n actual:** 0.0.7  
**Estado:** Pendiente de inicio
